# CIFAR-ViT: Vision Transformer å›¾åƒåˆ†ç±»å®éªŒ

<div align="center">

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

</div>

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®å®ç°äº†åŸºäº PyTorch çš„ Vision Transformer (ViT)ï¼Œåœ¨ CIFAR-10 æ•°æ®é›†ä¸Šè¿›è¡Œå›¾åƒåˆ†ç±»ä»»åŠ¡ã€‚é¡¹ç›®åŒ…å«æ ‡å‡† ViT ä»¥åŠä¸¤ç§è½»é‡åŒ–å˜ä½“æ¨¡å‹ï¼Œå¹¶å¯¹ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜æä¾›äº†è§£å†³æ–¹æ¡ˆã€‚

### å®éªŒè¦æ±‚

æ ¹æ®ã€Šæ·±åº¦å­¦ä¹ ä¸è®¡ç®—æœºè§†è§‰ã€‹è¯¾ç¨‹å®éªŒè¦æ±‚ï¼š

1. âœ… å®ç°æ ‡å‡† Vision Transformer æ¨¡å‹
2. âœ… åœ¨ CIFAR-10 æ•°æ®é›†ä¸Šè®­ç»ƒå’Œè¯„ä¼°
3. âœ… å¤„ç†ç±»åˆ«ä¸å¹³è¡¡æ•°æ®é›†ï¼ˆCIFAR10_imbalancedï¼‰
4. âœ… å®ç°è‡³å°‘2ç§ ViT è½»é‡åŒ–æ–¹æ³•é™ä½æ¨¡å‹å¤æ‚åº¦
5. âœ… è¿›è¡Œæ¨¡å‹å¤æ‚åº¦åˆ†æï¼ˆå‚æ•°é‡ã€FLOPsï¼‰
6. âœ… æä¾›å®Œæ•´çš„å®éªŒæŠ¥å‘Šå’Œä»£ç 

## ğŸ¯ ä¸»è¦ç‰¹æ€§

- **å¤šç§ ViT æ¨¡å‹**: æ ‡å‡† ViT-Baseã€ViT-Smallã€Dynamic ViTã€Lightweight ViT
- **ç±»åˆ«ä¸å¹³è¡¡å¤„ç†**: æ”¯æŒåŠ æƒé‡‡æ ·å’ŒæŸå¤±å‡½æ•°ç±»åˆ«æƒé‡
- **æ•°æ®å¢å¼º**: MixUpã€CutMixã€Cutout ç­‰å¤šç§å¢å¼ºç­–ç•¥
- **æ¨¡å‹è½»é‡åŒ–**: 
  - Dynamic ViT: åŠ¨æ€ token å‰ªæ
  - Lightweight ViT: é«˜æ•ˆçº¿æ€§æ³¨æ„åŠ›æœºåˆ¶
- **å®Œæ•´å·¥å…·é“¾**: è®­ç»ƒã€è¯„ä¼°ã€å¯è§†åŒ–ã€å¤æ‚åº¦åˆ†æ
- **å®éªŒç®¡ç†**: TensorBoard æ—¥å¿—ã€æ¨¡å‹æ£€æŸ¥ç‚¹ã€é…ç½®æ–‡ä»¶ç®¡ç†

## ğŸ“ é¡¹ç›®ç»“æ„


 CIFAR-ViT/
 â”œâ”€â”€ data/ # æ•°æ®ç›®å½•
 â”‚ â”œâ”€â”€ cifar10/ # CIFAR-10 æ•°æ®é›†
 â”‚ â””â”€â”€ download_data.py # æ•°æ®ä¸‹è½½è„šæœ¬
 â”œâ”€â”€ models/ # æ¨¡å‹å®šä¹‰
 â”‚ â”œâ”€â”€ vit.py # æ ‡å‡† ViT
 â”‚ â”œâ”€â”€ vit_variants.py # ViT å˜ä½“æ¨¡å‹
 â”‚ â”œâ”€â”€ patch_embedding.py # Patch åµŒå…¥å±‚
 â”‚ â”œâ”€â”€ attention.py # æ³¨æ„åŠ›æœºåˆ¶
 â”‚ â””â”€â”€ transformer_block.py # Transformer å—
 â”œâ”€â”€ utils/ # å·¥å…·å‡½æ•°
 â”‚ â”œâ”€â”€ data_loader.py # æ•°æ®åŠ è½½
 â”‚ â”œâ”€â”€ augmentation.py # æ•°æ®å¢å¼º
 â”‚ â”œâ”€â”€ metrics.py # è¯„ä¼°æŒ‡æ ‡
 â”‚ â””â”€â”€ visualization.py # å¯è§†åŒ–å·¥å…·
 â”œâ”€â”€ train/ # è®­ç»ƒç›¸å…³
 â”‚ â”œâ”€â”€ trainer.py # è®­ç»ƒå™¨
 â”‚ â”œâ”€â”€ train_balanced.py # å¹³è¡¡æ•°æ®è®­ç»ƒ
 â”‚ â””â”€â”€ train_imbalanced.py # ä¸å¹³è¡¡æ•°æ®è®­ç»ƒ
 â”œâ”€â”€ evaluation/ # è¯„ä¼°ç›¸å…³
 â”‚ â”œâ”€â”€ evaluate.py # æ¨¡å‹è¯„ä¼°
 â”‚ â””â”€â”€ complexity_analysis.py # å¤æ‚åº¦åˆ†æ
 â”œâ”€â”€ experiments/ # å®éªŒé…ç½®å’Œç»“æœ
 â”‚ â”œâ”€â”€ configs/ # é…ç½®æ–‡ä»¶
 â”‚ â””â”€â”€ results/ # å®éªŒç»“æœ
 â”œâ”€â”€ scripts/ # è¿è¡Œè„šæœ¬
 â”‚ â”œâ”€â”€ run_training.sh # è®­ç»ƒè„šæœ¬
 â”‚ â”œâ”€â”€ run_evaluation.sh # è¯„ä¼°è„šæœ¬
 â”‚ â””â”€â”€ export_results.sh # ç»“æœå¯¼å‡º
 â”œâ”€â”€ docs/ # æ–‡æ¡£
 â”œâ”€â”€ tests/ # å•å…ƒæµ‹è¯•
 â”œâ”€â”€ main.py # ä¸»ç¨‹åºå…¥å£
 â”œâ”€â”€ requirements.txt # ä¾èµ–åŒ…
 â””â”€â”€ README.md # é¡¹ç›®è¯´æ˜
 text

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒé…ç½®


 å…‹éš†é¡¹ç›®
 git clone https://github.com/yourusername/CIFAR-ViT.git
 cd CIFAR-ViT
 åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èï¼‰
 conda create -n cifar-vit python=3.8
conda åˆ›å»º-n cifar-vit python=3.8
 conda activate cifar-vit  conda æ¿€æ´» cifar-vit
 å®‰è£…ä¾èµ–
 pip install -r requirements.txt
pip å®‰è£… -r è¦æ±‚.txt
 text

### 2. æ•°æ®å‡†å¤‡


 ä¸‹è½½ CIFAR-10 æ•°æ®é›†å¹¶åˆ›å»ºä¸å¹³è¡¡ç‰ˆæœ¬
 python data/download_data.py
python æ•°æ®/download_data.py
 text

### 3. è®­ç»ƒæ¨¡å‹

#### æ–¹å¼ä¸€ï¼šä½¿ç”¨ä¸»ç¨‹åº


 è®­ç»ƒ ViT-Baseï¼ˆå¹³è¡¡æ•°æ®é›†ï¼‰
 python main.py train --config experiments/configs/vit_base.yaml
python main.py train --config å®éªŒ/configs/vit_base.yaml
 è®­ç»ƒ ViT-Baseï¼ˆä¸å¹³è¡¡æ•°æ®é›†ï¼‰
 python main.py train --config experiments/configs/vit_base.yaml --imbalanced
 è®­ç»ƒ Dynamic ViT
 python main.py train --config experiments/configs/dynamic_vit.yaml
python main.py train --config å®éªŒ/configs/dynamic_vit.yaml
 è®­ç»ƒ Lightweight ViT
 python main.py train --config experiments/configs/avit.yaml
python main.py train --config å®éªŒ/configs/avit.yaml
 text

#### æ–¹å¼äºŒï¼šä½¿ç”¨è®­ç»ƒè„šæœ¬


 åœ¨å¹³è¡¡æ•°æ®é›†ä¸Šè®­ç»ƒ
 python train/train_balanced.py --config experiments/configs/vit_base.yaml
python train/train_balanced.py --config å®éªŒ/configs/vit_base.yaml
 åœ¨ä¸å¹³è¡¡æ•°æ®é›†ä¸Šè®­ç»ƒ
 python train/train_imbalanced.py --config experiments/configs/vit_base.yaml
python train/train_imbalanced.py --config å®éªŒ/configs/vit_base.yaml
 text

#### æ–¹å¼ä¸‰ï¼šæ‰¹é‡è®­ç»ƒï¼ˆä½¿ç”¨shellè„šæœ¬ï¼‰


 chmod +x scripts/run_training.sh
chmod +x è„šæœ¬/run_training.sh
 ./scripts/run_training.sh
 text

### 4. è¯„ä¼°æ¨¡å‹


 è¯„ä¼°è®­ç»ƒå¥½çš„æ¨¡å‹
 python main.py evaluate   python main.py è¯„ä¼°
 --config experiments/configs/vit_base.yaml 
--é…ç½®å®éªŒ/configs/vit_base.yaml
 --checkpoint experiments/results/checkpoints/vit_base/best_model.pth
--æ£€æŸ¥ç‚¹å®éªŒ/ç»“æœ/æ£€æŸ¥ç‚¹/vit_base/best_model.pth
 æˆ–ä½¿ç”¨è¯„ä¼°è„šæœ¬
 chmod +x scripts/run_evaluation.sh
chmod +x è„šæœ¬/run_evaluation.sh
 ./scripts/run_evaluation.sh
 text

### 5. å¤æ‚åº¦åˆ†æ


 åˆ†ææ‰€æœ‰æ¨¡å‹
 python main.py analyze --config experiments/configs/vit_base.yaml
python main.py åˆ†æ --config å®éªŒ/configs/vit_base.yaml
 åˆ†ææŒ‡å®šæ¨¡å‹
 python main.py analyze --config experiments/configs/vit_base.yaml 
python main.py åˆ†æ --config å®éªŒ/configs/vit_base.yaml
 --models vit_base dynamic_vit
 text

## ğŸ“Š æ¨¡å‹å¯¹æ¯”

| æ¨¡å‹ | å‚æ•°é‡ | FLOPs | å‡†ç¡®ç‡ | æ¨ç†æ—¶é—´ |
|------|--------|-------|--------|----------|
| ViT-Base | 8.5M | 1.2G | ~85% | 15ms |
| ViT-Small | 6.0M | 0.8G | ~83% | 12ms |
| Dynamic ViT | 5.2M | 0.6G | ~84% | 10ms |
| Lightweight ViT | 4.8M | 0.5G | ~82% | 8ms |

*æ³¨ï¼šå®é™…æ€§èƒ½éœ€è¦åœ¨ä½ çš„ç¡¬ä»¶ä¸Šæµ‹è¯•*

## ğŸ”§ é…ç½®è¯´æ˜

é…ç½®æ–‡ä»¶ä½äº `experiments/configs/` ç›®å½•ä¸‹ï¼Œä¸»è¦å‚æ•°åŒ…æ‹¬ï¼š


 æ¨¡å‹é…ç½®
 model_type: 'vit_base' # æ¨¡å‹ç±»å‹
 img_size: 32 # å›¾åƒå¤§å°
 embed_dim: 512 # åµŒå…¥ç»´åº¦
 depth: 6 # Transformer å±‚æ•°
 num_heads: 8 # æ³¨æ„åŠ›å¤´æ•°
 è®­ç»ƒé…ç½®
 epochs: 100 # è®­ç»ƒè½®æ•°
 batch_size: 128 # æ‰¹æ¬¡å¤§å°
 learning_rate: 0.0003 # å­¦ä¹ ç‡
 optimizer: 'adamw' # ä¼˜åŒ–å™¨
 æ•°æ®å¢å¼º
 use_mixup: true # æ˜¯å¦ä½¿ç”¨ MixUp
 use_cutmix: true # æ˜¯å¦ä½¿ç”¨ CutMix
 ä¸å¹³è¡¡æ•°æ®å¤„ç†
 use_class_weights: true # ä½¿ç”¨ç±»åˆ«æƒé‡
 use_weighted_sampler: false # ä½¿ç”¨åŠ æƒé‡‡æ ·
 text

## ğŸ“ˆ å®éªŒç»“æœ

### è®­ç»ƒæ›²çº¿

è®­ç»ƒè¿‡ç¨‹ä¸­çš„æŸå¤±å’Œå‡†ç¡®ç‡æ›²çº¿ä¼šè‡ªåŠ¨ä¿å­˜åˆ° `experiments/results/checkpoints/` ç›®å½•ã€‚

### è¯„ä¼°æŒ‡æ ‡

- å‡†ç¡®ç‡ (Accuracy)
- ç²¾ç¡®ç‡ (Precision)
- å¬å›ç‡ (Recall)
- F1 åˆ†æ•° (F1-Score)
- æ··æ·†çŸ©é˜µ (Confusion Matrix)

### å¯è§†åŒ–

æ‰€æœ‰å¯è§†åŒ–ç»“æœï¼ˆè®­ç»ƒæ›²çº¿ã€æ··æ·†çŸ©é˜µã€æ³¨æ„åŠ›å›¾ç­‰ï¼‰ä¼šä¿å­˜åˆ° `experiments/results/figures/` ç›®å½•ã€‚

## ğŸ“ å®éªŒæŠ¥å‘Š

è¯¦ç»†çš„å®éªŒæŠ¥å‘Šè¯·å‚è€ƒ `docs/experiment_report.md`ï¼ŒåŒ…å«ï¼š

1. å®éªŒèƒŒæ™¯å’Œç›®çš„
2. æ¨¡å‹æ¶æ„è¯´æ˜
3. å®éªŒè®¾ç½®å’Œé…ç½®
4. å®éªŒç»“æœå’Œåˆ†æ
5. ç»“è®ºå’Œæ”¹è¿›æ–¹å‘

## ğŸ’¡ ä½¿ç”¨æŠ€å·§

### å¤„ç†ç±»åˆ«ä¸å¹³è¡¡

é¡¹ç›®æä¾›ä¸¤ç§æ–¹æ³•å¤„ç†ç±»åˆ«ä¸å¹³è¡¡ï¼š

1. **åŠ æƒé‡‡æ ·** (Weighted Sampling)

 use_weighted_sampler: true
ä½¿ç”¨åŠ æƒé‡‡æ ·å™¨ï¼štrue
 text

2. **ç±»åˆ«æƒé‡æŸå¤±** (Class-weighted Loss)

 use_class_weights: true  use_class_weightsï¼štrue
 text

### å‡å°‘è¿‡æ‹Ÿåˆ

- ä½¿ç”¨æ•°æ®å¢å¼ºï¼šMixUpã€CutMixã€Cutout
- è°ƒæ•´ dropout ç‡
- ä½¿ç”¨æ ‡ç­¾å¹³æ»‘ (Label Smoothing)
- å‡å°æ¨¡å‹å¤§å°

### æå‡è®­ç»ƒé€Ÿåº¦

- å¢åŠ  batch sizeï¼ˆå¦‚æœæ˜¾å­˜å…è®¸ï¼‰
- ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆéœ€è¦ PyTorch AMPï¼‰
- ä½¿ç”¨å¤š GPU è®­ç»ƒ
- å‡å°‘æ•°æ®åŠ è½½çº¿ç¨‹æ•°

## ğŸ› å¸¸è§é—®é¢˜

### 1. CUDA out of memory

å‡å° batch size æˆ–ä½¿ç”¨æ›´å°çš„æ¨¡å‹ï¼š

 batch_size: 64 # é™ä½ batch size
 model_type: 'vit_small' # ä½¿ç”¨æ›´å°çš„æ¨¡å‹
 text

### 2. æ•°æ®åŠ è½½æ…¢

è°ƒæ•´æ•°æ®åŠ è½½å™¨å‚æ•°ï¼š

 num_workers: 8 # å¢åŠ å·¥ä½œçº¿ç¨‹
 pin_memory: true # å¯ç”¨ pin memory
 text

### 3. è®­ç»ƒä¸æ”¶æ•›

- é™ä½å­¦ä¹ ç‡
- ä½¿ç”¨å­¦ä¹ ç‡é¢„çƒ­ (warmup)
- æ£€æŸ¥æ•°æ®å¢å¼ºæ˜¯å¦è¿‡å¼º
- å°è¯•ä¸åŒçš„ä¼˜åŒ–å™¨

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. Dosovitskiy, A., et al. (2020). "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale." ICLR 2021.
2. Rao, Y., et al. (2021). "DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification." NeurIPS 2021.
3. Wang, S., et al. (2021). "Linformer: Self-Attention with Linear Complexity." arXiv:2006.04768.

## ğŸ‘¥ å›¢é˜Ÿåˆ†å·¥

- **Haonan Wang**: æ¨¡å‹å®ç°ã€è®­ç»ƒæ¡†æ¶æ­å»ºã€æ•°æ®å¤„ç†ã€è¯„ä¼°æŒ‡æ ‡å®ç°ã€å¯è§†åŒ–ã€å®éªŒåˆ†æã€æ–‡æ¡£ç¼–å†™


## ğŸ“ License

æœ¬é¡¹ç›®é‡‡ç”¨ MIT License - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ“§ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜ï¼Œè¯·è”ç³»ï¼šnhao4968@gmail.com

---

<div align="center">
Made with â¤ï¸ for Deep Learning and Computer Vision Course
</div>
